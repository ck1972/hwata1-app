# -*- coding: utf-8 -*-
"""HWATA1a.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19fjdApKHRJrcXujeXRJ8W3nHIXdzN2UR
"""

# hwata1a.py
# HWATA 1: Streamlit App for Regularized Building Footprint Extraction (no gdown)

import os
import hashlib
from tempfile import NamedTemporaryFile

import requests
import streamlit as st
import geopandas as gpd
import rasterio
import numpy as np
import torch
from rasterio import features
import segmentation_models_pytorch as smp
from buildingregulariser import regularize_geodataframe
import folium
from streamlit_folium import st_folium


# ====================== CONFIG ======================
# Public GitHub Release asset URL (change if your tag/filename differ)
MODEL_URL = (
    "https://github.com/ck1972/hwata1-app/releases/download/"
    "v0.1.0/pretrained_unet_building_segmentation.pth"
)
MODEL_PATH = "pretrained_unet_building_segmentation.pth"

# Optional: integrity check (paste the real SHA-256 of your .pth)
MODEL_SHA256 = ""  # e.g., "a4b2c3..."; leave "" to skip


# ====================== PAGE ======================
st.set_page_config(page_title="HWATA 1 ‚Äì GeoAI Feature Extractor", layout="centered")
st.title("üè† HWATA 1 ‚Äì Building Footprint Extractor")
st.markdown(
    "Upload a 30 cm satellite or aerial image (GeoTIFF), and HWATA 1 will "
    "extract **regularized** building footprints as GeoJSON."
)


# ====================== HELPERS ======================
def _sha256(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1 << 20), b""):
            h.update(chunk)
    return h.hexdigest()


@st.cache_resource
def fetch_model_file() -> str:
    """
    Ensure MODEL_PATH exists locally; download from GitHub Release if missing
    (or if checksum fails). Returns the local path.
    """
    if os.path.exists(MODEL_PATH):
        if MODEL_SHA256:
            if _sha256(MODEL_PATH) == MODEL_SHA256:
                return MODEL_PATH
            # if checksum mismatch, re-download
            os.remove(MODEL_PATH)
        else:
            return MODEL_PATH

    st.info("Downloading model from GitHub Releases‚Ä¶")
    headers = {}
    # For private releases, add a token in Streamlit Secrets
    if "GITHUB_TOKEN" in st.secrets:
        headers["Authorization"] = f"Bearer {st.secrets['GITHUB_TOKEN']}"

    with requests.get(MODEL_URL, headers=headers, stream=True, timeout=120) as r:
        r.raise_for_status()
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(1 << 20):
                if chunk:
                    f.write(chunk)

    if MODEL_SHA256:
        digest = _sha256(MODEL_PATH)
        assert digest == MODEL_SHA256, f"Model checksum mismatch: {digest}"

    return MODEL_PATH


@st.cache_resource
def load_model(model_path: str, device: torch.device):
    """
    Build UNet, load weights, set eval, and cache the instance.
    """
    model = smp.Unet(
        encoder_name="resnet34",
        encoder_weights="imagenet",
        in_channels=3,
        classes=1,
    ).to(device)
    state = torch.load(model_path, map_location=device)
    model.load_state_dict(state)
    model.eval()
    return model


def quick_raster_probe(path: str):
    """
    Return basic raster info to help pinpoint I/O issues fast.
    """
    with rasterio.open(path) as src:
        return {
            "width": src.width,
            "height": src.height,
            "bands": src.count,
            "dtype": src.dtypes[0],
            "crs": str(src.crs),
        }


# ====================== UI: FILE UPLOAD ======================
uploaded_img = st.file_uploader("üìÇ Upload 30 cm Image (GeoTIFF)", type=["tif", "tiff"])

if uploaded_img:
    with NamedTemporaryFile(delete=False, suffix=".tif") as tmp_img:
        tmp_img.write(uploaded_img.read())
        tmp_img_path = tmp_img.name

    st.success("‚úÖ Image uploaded. Running prediction‚Ä¶")

    # --- Probe raster (fast feedback if file is invalid) ---
    try:
        info = quick_raster_probe(tmp_img_path)
        st.caption(f"Raster info ‚Üí {info}")
    except Exception as e:
        st.error(f"Raster read failed ‚ùå: {e}")
        os.remove(tmp_img_path)
        st.stop()

    # --- Load raster ---
    with rasterio.open(tmp_img_path) as src:
        # Use only RGB channels for this model
        image = src.read([1, 2, 3])
        transform = src.transform
        height, width = src.height, src.width
        raster_crs = src.crs

    # Normalize to [0,1] float32
    image = image.astype(np.float32) / 255.0

    # --- Ensure model file is present (no gdown) ---
    try:
        model_path = fetch_model_file()
        st.success("‚úÖ Model ready")
        st.caption(
            {
                "model_path": model_path,
                "exists": os.path.exists(model_path),
                "size_bytes": os.path.getsize(model_path)
                if os.path.exists(model_path)
                else 0,
            }
        )
    except Exception as e:
        st.error(f"Model fetch failed ‚ùå: {e}")
        st.info(
            "If the release is private, add GITHUB_TOKEN in Streamlit Secrets "
            "and redeploy."
        )
        os.remove(tmp_img_path)
        st.stop()

    # --- Load model ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    try:
        model = load_model(model_path, device)
    except Exception as e:
        st.error(f"Model load failed ‚ùå: {e}")
        os.remove(tmp_img_path)
        st.stop()

    # --- Predict mask (simple sliding window over non-overlapping tiles) ---
    patch_size = 256
    full_pred_mask = np.zeros((height, width), dtype=np.uint8)

    with torch.no_grad():
        for i in range(0, height - patch_size + 1, patch_size):
            for j in range(0, width - patch_size + 1, patch_size):
                patch = image[:, i : i + patch_size, j : j + patch_size]
                if patch.shape[1:] != (patch_size, patch_size):
                    continue
                patch_tensor = torch.from_numpy(patch).float().unsqueeze(0).to(device)
                output = torch.sigmoid(model(patch_tensor))
                pred_patch = (output.squeeze().cpu().numpy() > 0.5).astype(np.uint8)
                full_pred_mask[i : i + patch_size, j : j + patch_size] = pred_patch

    st.success("‚úÖ Prediction completed. Converting to GeoJSON‚Ä¶")

    # --- Raster mask ‚Üí polygons ---
    results = (
        {"properties": {"raster_val": v}, "geometry": s}
        for s, v in features.shapes(
            full_pred_mask.astype(np.int16), transform=transform
        )
        if v == 1
    )
    gdf_pred = gpd.GeoDataFrame.from_features(list(results), crs=raster_crs)

    # --- Filter small pieces & regularize ---
    if len(gdf_pred) == 0:
        st.warning("No building polygons detected. Try a clearer 30 cm image.")
        os.remove(tmp_img_path)
        st.stop()

    gdf_proj = gdf_pred.to_crs(gdf_pred.estimate_utm_crs())
    gdf_proj["area_m2"] = gdf_proj.geometry.area
    gdf_filtered = gdf_proj[gdf_proj["area_m2"] >= 10].to_crs(raster_crs)

    try:
        polygons = regularize_geodataframe(gdf_filtered)
    except Exception as e:
        st.warning(f"Regularization issue (showing unregularized polygons): {e}")
        polygons = gdf_filtered.copy()

    # Reproject for map/export
    polygons = polygons.to_crs(epsg=4326)

    st.success("‚úÖ Building footprints extracted and regularized.")

    # --- Preview on map (optional) ---
    if st.checkbox("üåç Preview Building Footprints on Google Satellite"):
        st.subheader("üó∫Ô∏è Interactive Preview")
        bounds = polygons.total_bounds  # [minx, miny, maxx, maxy]
        center_lat = (bounds[1] + bounds[3]) / 2
        center_lon = (bounds[0] + bounds[2]) / 2

        m = folium.Map(location=[center_lat, center_lon], zoom_start=18)
        folium.TileLayer(
            tiles="https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}",
            attr="Google Satellite",
            name="Google Satellite",
            overlay=False,
            control=True,
        ).add_to(m)

        folium.GeoJson(
            polygons,
            name="Building Footprints",
            style_function=lambda x: {"color": "cyan", "weight": 1.5, "fillOpacity": 0.3},
        ).add_to(m)

        st_folium(m, width=700, height=500)

    # --- Download GeoJSON ---
    st.subheader("üì• Download Extracted Footprints")
    st.download_button(
        "üìÑ Download GeoJSON",
        polygons.to_json(),
        file_name="building_footprints.geojson",
        mime="application/geo+json",
    )

    # Cleanup
    try:
        os.remove(tmp_img_path)
    except Exception:
        pass