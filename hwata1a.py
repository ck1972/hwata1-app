# -*- coding: utf-8 -*-
"""HWATA1a.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19fjdApKHRJrcXujeXRJ8W3nHIXdzN2UR
"""

# hwata1a.py
# HWATA 1: Streamlit App for Regularized Building Footprint Extraction (no gdown)
# Robust to checkpoints with 1 or 2 output classes.

import os
import hashlib
from tempfile import NamedTemporaryFile

import requests
import streamlit as st
import geopandas as gpd
import rasterio
import numpy as np
import torch
from rasterio import features
import segmentation_models_pytorch as smp
from buildingregulariser import regularize_geodataframe
import folium
from streamlit_folium import st_folium


# ====================== CONFIG ======================
MODEL_URL = (
    "https://github.com/ck1972/hwata1-app/releases/download/"
    "v0.1.0/pretrained_unet_building_segmentation.pth"
)
MODEL_PATH = "pretrained_unet_building_segmentation.pth"
MODEL_SHA256 = ""  # optional; paste your real sha256 to verify downloads


# ====================== PAGE ======================
st.set_page_config(page_title="HWATA 1 ‚Äì GeoAI Feature Extractor", layout="centered")
st.title("üè† HWATA 1 ‚Äì Building Footprint Extractor")
st.markdown(
    "Upload a 30 cm satellite or aerial image (GeoTIFF) and HWATA 1 will "
    "extract **regularized** building footprints as GeoJSON."
)


# ====================== HELPERS ======================
def _sha256(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1 << 20), b""):
            h.update(chunk)
    return h.hexdigest()


@st.cache_resource
def fetch_model_file() -> str:
    """Ensure MODEL_PATH exists locally; download from GitHub Release if missing."""
    if os.path.exists(MODEL_PATH):
        if MODEL_SHA256:
            if _sha256(MODEL_PATH) == MODEL_SHA256:
                return MODEL_PATH
            os.remove(MODEL_PATH)  # re-download if checksum mismatch
        else:
            return MODEL_PATH

    st.info("Downloading model from GitHub Releases‚Ä¶")
    headers = {}
    if "GITHUB_TOKEN" in st.secrets:  # only needed for private releases
        headers["Authorization"] = f"Bearer {st.secrets['GITHUB_TOKEN']}"

    with requests.get(MODEL_URL, headers=headers, stream=True, timeout=120) as r:
        r.raise_for_status()
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(1 << 20):
                if chunk:
                    f.write(chunk)

    if MODEL_SHA256:
        digest = _sha256(MODEL_PATH)
        assert digest == MODEL_SHA256, f"Model checksum mismatch: {digest}"

    return MODEL_PATH


def _infer_num_classes_from_state(state_dict: dict, default: int = 1) -> int:
    """
    Try to infer #classes from the segmentation head weight tensor in the checkpoint.
    Looks for 'segmentation_head.0.weight' which has shape [C_out, C_in, k, k].
    """
    w = state_dict.get("segmentation_head.0.weight", None)
    if w is None and "module.segmentation_head.0.weight" in state_dict:
        w = state_dict["module.segmentation_head.0.weight"]
    if isinstance(w, torch.Tensor) and w.ndim == 4:
        return int(w.shape[0])
    return default


@st.cache_resource
def load_model(model_path: str, device: torch.device):
    """
    Build UNet with the correct #classes inferred from the checkpoint, load weights, eval().
    """
    raw_state = torch.load(model_path, map_location="cpu")  # load on CPU first
    # Some training scripts wrap the state under a 'state_dict' key
    if isinstance(raw_state, dict) and "state_dict" in raw_state:
        state_dict = raw_state["state_dict"]
    else:
        state_dict = raw_state

    num_classes = _infer_num_classes_from_state(state_dict, default=1)

    model = smp.Unet(
        encoder_name="resnet34",
        encoder_weights="imagenet",
        in_channels=3,
        classes=num_classes,          # <-- match checkpoint
        activation=None,              # we'll handle sigmoid/softmax manually
    ).to(device)

    # Load weights (allow strict load; should match now that classes align)
    model.load_state_dict(state_dict, strict=True)
    model.eval()
    return model, num_classes


def quick_raster_probe(path: str):
    """Return basic raster info to help pinpoint file issues quickly."""
    with rasterio.open(path) as src:
        return {
            "width": src.width,
            "height": src.height,
            "bands": src.count,
            "dtype": src.dtypes[0],
            "crs": str(src.crs),
        }


def logits_to_building_prob(logits: torch.Tensor) -> torch.Tensor:
    """
    Convert model logits to a single-channel building probability map.
    - If logits.shape[1] == 1 ‚Üí sigmoid
    - If logits.shape[1] == 2 ‚Üí softmax and take channel 1 as 'building'
      (assumes channel 0 = background, channel 1 = building)
    Returns a tensor of shape [B, 1, H, W]
    """
    if logits.shape[1] == 1:
        prob = torch.sigmoid(logits)
    else:
        # softmax over channels, keep class-1 (building) as [B,1,H,W]
        prob1 = torch.softmax(logits, dim=1)[:, 1:2, ...]
        prob = prob1
    return prob


# ====================== UI: FILE UPLOAD ======================
uploaded_img = st.file_uploader("üìÇ Upload 30 cm Image (GeoTIFF)", type=["tif", "tiff"])

if uploaded_img:
    with NamedTemporaryFile(delete=False, suffix=".tif") as tmp_img:
        tmp_img.write(uploaded_img.read())
        tmp_img_path = tmp_img.name

    st.success("‚úÖ Image uploaded. Running prediction‚Ä¶")

    # --- Probe raster (fast feedback if file is invalid) ---
    try:
        info = quick_raster_probe(tmp_img_path)
        st.caption(f"Raster info ‚Üí {info}")
    except Exception as e:
        st.error(f"Raster read failed ‚ùå: {e}")
        try:
            os.remove(tmp_img_path)
        except Exception:
            pass
        st.stop()

    # --- Load raster ---
    with rasterio.open(tmp_img_path) as src:
        # Use only RGB channels for this model
        image = src.read([1, 2, 3])
        transform = src.transform
        height, width = src.height, src.width
        raster_crs = src.crs

    # Normalize to [0,1] float32
    image = image.astype(np.float32) / 255.0

    # --- Ensure model file is present ---
    try:
        model_path = fetch_model_file()
        st.caption(
            {
                "model_path": model_path,
                "exists": os.path.exists(model_path),
                "size_bytes": os.path.getsize(model_path)
                if os.path.exists(model_path)
                else 0,
            }
        )
    except Exception as e:
        st.error(f"Model fetch failed ‚ùå: {e}")
        try:
            os.remove(tmp_img_path)
        except Exception:
            pass
        st.stop()

    # --- Load model (now robust to 1 vs 2 classes) ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    try:
        model, num_classes = load_model(model_path, device)
        st.success(f"‚úÖ Model ready (classes={num_classes})")
    except Exception as e:
        st.error(f"Model load failed ‚ùå: {e}")
        try:
            os.remove(tmp_img_path)
        except Exception:
            pass
        st.stop()

    # --- Predict mask (sliding window, non-overlapping tiles) ---
    patch_size = 256
    full_pred_mask = np.zeros((height, width), dtype=np.uint8)

    with torch.no_grad():
        for i in range(0, height - patch_size + 1, patch_size):
            for j in range(0, width - patch_size + 1, patch_size):
                patch = image[:, i : i + patch_size, j : j + patch_size]
                if patch.shape[1:] != (patch_size, patch_size):
                    continue
                patch_tensor = torch.from_numpy(patch).float().unsqueeze(0).to(device)
                logits = model(patch_tensor)
                prob = logits_to_building_prob(logits)            # [B,1,H,W]
                pred_patch = (prob.squeeze().cpu().numpy() > 0.5).astype(np.uint8)
                full_pred_mask[i : i + patch_size, j : j + patch_size] = pred_patch

    st.success("‚úÖ Prediction completed. Converting to GeoJSON‚Ä¶")

    # --- Raster mask ‚Üí polygons ---
    results = (
        {"properties": {"raster_val": v}, "geometry": s}
        for s, v in features.shapes(
            full_pred_mask.astype(np.int16), transform=transform
        )
        if v == 1
    )
    gdf_pred = gpd.GeoDataFrame.from_features(list(results), crs=raster_crs)

    # --- Filter small pieces & regularize ---
    if len(gdf_pred) == 0:
        st.warning("No building polygons detected. Try a clearer 30 cm image.")
        try:
            os.remove(tmp_img_path)
        except Exception:
            pass
        st.stop()

    gdf_proj = gdf_pred.to_crs(gdf_pred.estimate_utm_crs())
    gdf_proj["area_m2"] = gdf_proj.geometry.area
    gdf_filtered = gdf_proj[gdf_proj["area_m2"] >= 10].to_crs(raster_crs)

    try:
        polygons = regularize_geodataframe(gdf_filtered)
    except Exception as e:
        st.warning(f"Regularization issue (showing unregularized polygons): {e}")
        polygons = gdf_filtered.copy()

    # Reproject for map/export
    polygons = polygons.to_crs(epsg=4326)

    st.success("‚úÖ Building footprints extracted and regularized.")

    # --- Preview on map (optional) ---
    if st.checkbox("üåç Preview Building Footprints on Google Satellite"):
        st.subheader("üó∫Ô∏è Interactive Preview")
        bounds = polygons.total_bounds  # [minx, miny, maxx, maxy]
        center_lat = (bounds[1] + bounds[3]) / 2
        center_lon = (bounds[0] + bounds[2]) / 2

        m = folium.Map(location=[center_lat, center_lon], zoom_start=18)
        folium.TileLayer(
            tiles="https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}",
            attr="Google Satellite",
            name="Google Satellite",
            overlay=False,
            control=True,
        ).add_to(m)

        folium.GeoJson(
            polygons,
            name="Building Footprints",
            style_function=lambda x: {"color": "cyan", "weight": 1.5, "fillOpacity": 0.3},
        ).add_to(m)

        st_folium(m, width=700, height=500)

    # --- Download GeoJSON ---
    st.subheader("üì• Download Extracted Footprints")
    st.download_button(
        "üìÑ Download GeoJSON",
        polygons.to_json(),
        file_name="building_footprints.geojson",
        mime="application/geo+json",
    )

    # Cleanup
    try:
        os.remove(tmp_img_path)
    except Exception:
        pass